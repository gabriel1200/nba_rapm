{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844a2cd-c6c0-4771-af49-9963f882fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'playoff_series.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Rename the columns and divide PTS by 100\n",
    "df['PTS'] = df['PTS'] / 100\n",
    "df = df.rename(columns={'PLAYER_ID': 'nba_id', 'PLAYER_NAME': 'player_name'})\n",
    "\n",
    "# Select the specified columns\n",
    "columns_to_keep = [\n",
    "    'nba_id', 'player_name', 'year', 'round', 'OPP', 'USG_PCT', 'TS_PCT',\n",
    "    'year_avg_ts', 'OPP_TS_PCT', 'rOPP_TS_PCT', 'GP', 'PTS', 'MIN', 'AGE',\n",
    "    'AST_PCT', 'POSS', 'OFF_RATING', 'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A',\n",
    "    'FG3_PCT', 'FTM', 'FTA', 'OREB', 'DREB', 'REB', 'AST', 'TOV', 'STL', 'BLK',\n",
    "    'BLKA', 'PF', 'PFD', 'PLUS_MINUS'\n",
    "]\n",
    "\n",
    "df_selected = df[columns_to_keep].copy()\n",
    "\n",
    "# Create TSA column\n",
    "df_selected['TSA'] = df_selected['FGA'] + 0.44 * df_selected['FTA']\n",
    "\n",
    "\n",
    "# Function to safely divide\n",
    "def safe_divide(a, b):\n",
    "    return np.where(b != 0, a / b, 0)\n",
    "\n",
    "\n",
    "# Function for weighted average\n",
    "def weighted_average(group, value_col, weight_col):\n",
    "    return (group[value_col] *\n",
    "            group[weight_col]).sum() / group[weight_col].sum()\n",
    "\n",
    "\n",
    "# Group by nba_id and year to roll up stats to the year\n",
    "grouped_df_corrected = df_selected.groupby(['nba_id', 'year']).sum({\n",
    "    'player_name':\n",
    "    'first',\n",
    "    'round':\n",
    "    lambda x: 'All',\n",
    "    'OPP':\n",
    "    lambda x: 'All',\n",
    "    'AGE':\n",
    "    'first',\n",
    "    'PTS':\n",
    "    'sum',\n",
    "    'GP':\n",
    "    'sum',\n",
    "    'MIN':\n",
    "    'sum',\n",
    "    'POSS':\n",
    "    'sum',\n",
    "    'TSA':\n",
    "    'sum',\n",
    "    'FGM':\n",
    "    'sum',\n",
    "    'FGA':\n",
    "    'sum',\n",
    "    'FG_PCT':\n",
    "    'mean',\n",
    "    'FG3M':\n",
    "    'sum',\n",
    "    'FG3A':\n",
    "    'sum',\n",
    "    'FG3_PCT':\n",
    "    'mean',\n",
    "    'FTM':\n",
    "    'sum',\n",
    "    'FTA':\n",
    "    'sum',\n",
    "    'OREB':\n",
    "    'sum',\n",
    "    'DREB':\n",
    "    'sum',\n",
    "    'REB':\n",
    "    'sum',\n",
    "    'AST':\n",
    "    'sum',\n",
    "    'TOV':\n",
    "    'sum',\n",
    "    'STL':\n",
    "    'sum',\n",
    "    'BLK':\n",
    "    'sum',\n",
    "    'BLKA':\n",
    "    'sum',\n",
    "    'PF':\n",
    "    'sum',\n",
    "    'PFD':\n",
    "    'sum',\n",
    "    'PLUS_MINUS':\n",
    "    'sum',\n",
    "    'AST_PCT':\n",
    "    lambda x: weighted_average(x, 'AST_PCT', 'POSS'),\n",
    "    'OFF_RATING':\n",
    "    lambda x: weighted_average(x, 'OFF_RATING', 'POSS'),\n",
    "    'USG_PCT':\n",
    "    lambda x: weighted_average(x, 'USG_PCT', 'POSS'),\n",
    "    'TS_PCT':\n",
    "    lambda x: weighted_average(x, 'TS_PCT', 'TSA'),\n",
    "    'year_avg_ts':\n",
    "    lambda x: weighted_average(x, 'year_avg_ts', 'TSA'),\n",
    "    'OPP_TS_PCT':\n",
    "    lambda x: weighted_average(x, 'OPP_TS_PCT', 'TSA'),\n",
    "    'rOPP_TS_PCT':\n",
    "    lambda x: weighted_average(x, 'rOPP_TS_PCT', 'TSA')\n",
    "}).reset_index()\n",
    "\n",
    "# Append the corrected rolled up rows to the original dataframe\n",
    "df_final_corrected = pd.concat([df_selected, grouped_df_corrected],\n",
    "                               ignore_index=True)\n",
    "\n",
    "# Roll up stats for each player across their career\n",
    "career_grouped_df = df_final_corrected[\n",
    "    df_final_corrected['round'] == 'All'].groupby(['nba_id']).agg({\n",
    "        'player_name':\n",
    "        'first',\n",
    "        'year':\n",
    "        lambda x: 'Career',\n",
    "        'round':\n",
    "        lambda x: 'Career',\n",
    "        'OPP':\n",
    "        lambda x: 'All',\n",
    "        'AGE':\n",
    "        'first',\n",
    "        'PTS':\n",
    "        'sum',\n",
    "        'GP':\n",
    "        'sum',\n",
    "        'MIN':\n",
    "        'sum',\n",
    "        'POSS':\n",
    "        'sum',\n",
    "        'TSA':\n",
    "        'sum',\n",
    "        'FGM':\n",
    "        'sum',\n",
    "        'FGA':\n",
    "        'sum',\n",
    "        'FG_PCT':\n",
    "        'mean',\n",
    "        'FG3M':\n",
    "        'sum',\n",
    "        'FG3A':\n",
    "        'sum',\n",
    "        'FG3_PCT':\n",
    "        'mean',\n",
    "        'FTM':\n",
    "        'sum',\n",
    "        'FTA':\n",
    "        'sum',\n",
    "        'OREB':\n",
    "        'sum',\n",
    "        'DREB':\n",
    "        'sum',\n",
    "        'REB':\n",
    "        'sum',\n",
    "        'AST':\n",
    "        'sum',\n",
    "        'TOV':\n",
    "        'sum',\n",
    "        'STL':\n",
    "        'sum',\n",
    "        'BLK':\n",
    "        'sum',\n",
    "        'BLKA':\n",
    "        'sum',\n",
    "        'PF':\n",
    "        'sum',\n",
    "        'PFD':\n",
    "        'sum',\n",
    "        'PLUS_MINUS':\n",
    "        'sum',\n",
    "        'AST_PCT':\n",
    "        lambda x: weighted_average(x, 'AST_PCT', 'POSS'),\n",
    "        'OFF_RATING':\n",
    "        lambda x: weighted_average(x, 'OFF_RATING', 'POSS'),\n",
    "        'USG_PCT':\n",
    "        lambda x: weighted_average(x, 'USG_PCT', 'POSS'),\n",
    "        'TS_PCT':\n",
    "        lambda x: weighted_average(x, 'TS_PCT', 'TSA'),\n",
    "        'year_avg_ts':\n",
    "        lambda x: weighted_average(x, 'year_avg_ts', 'TSA'),\n",
    "        'OPP_TS_PCT':\n",
    "        lambda x: weighted_average(x, 'OPP_TS_PCT', 'TSA'),\n",
    "        'rOPP_TS_PCT':\n",
    "        lambda x: weighted_average(x, 'rOPP_TS_PCT', 'TSA')\n",
    "    }).reset_index()\n",
    "\n",
    "# Append the career rolled up rows to the original dataframe\n",
    "df_final_with_career = pd.concat([df_final_corrected, career_grouped_df],\n",
    "                                 ignore_index=True)\n",
    "\n",
    "# Calculate derived statistics using safe division\n",
    "df_final_with_career['MPG'] = safe_divide(df_final_with_career['MIN'],\n",
    "                                          df_final_with_career['GP'])\n",
    "df_final_with_career['PPG'] = safe_divide(df_final_with_career['PTS'],\n",
    "                                          df_final_with_career['GP'])\n",
    "df_final_with_career['PTS/75'] = safe_divide(df_final_with_career['PTS'],\n",
    "                                             df_final_with_career['POSS']) * 75\n",
    "df_final_with_career['AST/75'] = safe_divide(df_final_with_career['AST'],\n",
    "                                             df_final_with_career['POSS']) * 75\n",
    "df_final_with_career['REB/75'] = safe_divide(df_final_with_career['REB'],\n",
    "                                             df_final_with_career['POSS']) * 75\n",
    "df_final_with_career['TOV/75'] = safe_divide(df_final_with_career['TOV'],\n",
    "                                             df_final_with_career['POSS']) * 75\n",
    "\n",
    "df_final_with_career['TSA/100'] = safe_divide(\n",
    "    df_final_with_career['TSA'] * 100, df_final_with_career['POSS'])\n",
    "df_final_with_career['TS_ADD'] = df_final_with_career[\n",
    "    'TSA'] * df_final_with_career['rOPP_TS_PCT'] * 2\n",
    "df_final_with_career['TS_ADD_1'] = df_final_with_career['TSA'] * (\n",
    "    df_final_with_career['rOPP_TS_PCT'] + 0.01) * 2\n",
    "df_final_with_career['TS_ADD_PER_100'] = safe_divide(\n",
    "    df_final_with_career['TS_ADD'] * 100, df_final_with_career['POSS'])\n",
    "df_final_with_career['TS_ADD_1_PER_100'] = safe_divide(\n",
    "    df_final_with_career['TS_ADD_1'] * 100, df_final_with_career['POSS'])\n",
    "\n",
    "# ... rest of the code remains the same\n",
    "\n",
    "# Separate the rows for 'Career'\n",
    "df_career = df_final_with_career[df_final_with_career['round'] == 'Career']\n",
    "\n",
    "# Separate the rows for 'All'\n",
    "df_all = df_final_with_career[df_final_with_career['round'] == 'All']\n",
    "\n",
    "# Get the other rounds\n",
    "df_rounds = df_final_with_career[(df_final_with_career['round'] != 'All')\n",
    "                                 & (df_final_with_career['round'] != 'Career')]\n",
    "\n",
    "# Create a dictionary to hold the nested structure\n",
    "nested_data = []\n",
    "\n",
    "for index, row in df_all.iterrows():\n",
    "    nba_id = row['nba_id']\n",
    "    year = row['year']\n",
    "\n",
    "    # Get the rounds for this player and year\n",
    "    rounds = df_rounds[(df_rounds['nba_id'] == nba_id)\n",
    "                       & (df_rounds['year'] == year)]\n",
    "\n",
    "    # Convert the rounds to a list of dictionaries\n",
    "    rounds_list = rounds.to_dict(orient='records')\n",
    "\n",
    "    # Add the rounds to the 'All' row\n",
    "    row['rounds'] = json.dumps(rounds_list)\n",
    "\n",
    "    # Append to the nested data list\n",
    "    nested_data.append(row)\n",
    "\n",
    "# Convert the nested data list to a DataFrame\n",
    "df_nested = pd.DataFrame(nested_data)\n",
    "\n",
    "# Concatenate with the career rows\n",
    "df_final_nested = pd.concat([df_nested, df_career], ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = 'nested_playoff_series.csv'\n",
    "df_final_nested.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
